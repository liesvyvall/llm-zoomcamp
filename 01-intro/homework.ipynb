{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72430cc-6d6a-46b6-8892-55516c64ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "{\n",
    "  \"name\" : \"56f843790c93\",\n",
    "  \"cluster_name\" : \"docker-cluster\",\n",
    "  \"cluster_uuid\" : \"jeW-UWoYR8KBg5-anwWq-Q\",\n",
    "  \"version\" : {\n",
    "    \"number\" : \"8.4.3\",\n",
    "    \"build_flavor\" : \"default\",\n",
    "    \"build_type\" : \"docker\",\n",
    "    \"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
    "    \"build_date\" : \"2022-10-04T07:17:24.662462378Z\",\n",
    "    \"build_snapshot\" : false,\n",
    "    \"lucene_version\" : \"9.3.0\",\n",
    "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
    "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
    "  },\n",
    "  \"tagline\" : \"You Know, for Search\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"build_hash\" : \"42f05b9372a9a4a470db3b52817899b99a76ee73\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3e57566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76947258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3055774c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a23e988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:22<00:00, 42.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aead7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which function do you use for adding your data to elastic?\n",
    "\n",
    "## We use index function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c2eee877",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_client.py:104\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    102\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "36c2e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question\", \"text\"],\n",
    "                        \"boost\": 4,\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs, response\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f38c942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results, response = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31dca323",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I execute a command in a running docker container?'\n",
    "ans, response = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "327a694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 87, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 865, 'relation': 'eq'}, 'max_score': 86.67784, 'hits': [{'_index': 'course-questions', '_id': 'SRacTJABVfXUHjPwxrd5', '_score': 86.67784, '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp'}}, {'_index': 'course-questions', '_id': 'aBacTJABVfXUHjPwybc1', '_score': 85.69645, '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\", 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from my local machine to docker container?', 'course': 'machine-learning-zoomcamp'}}, {'_index': 'course-questions', '_id': 'VxacTJABVfXUHjPwmLV1', '_score': 75.54128, '_source': {'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>', 'section': 'Module 1: Docker and Terraform', 'question': 'PGCLI - running in a Docker container', 'course': 'data-engineering-zoomcamp'}}, {'_index': 'course-questions', '_id': 'eBacTJABVfXUHjPw4bin', '_score': 72.08518, '_source': {'text': 'If you are trying to run Flask gunicorn & MLFlow server from the same container, defining both in Dockerfile with CMD will only run MLFlow & not Flask.\\nSolution: Create separate shell script with server run commands, for eg:\\n> \\tscript1.sh\\n#!/bin/bash\\ngunicorn --bind=0.0.0.0:9696 predict:app\\nAnother script with e.g. MLFlow server:\\n>\\tscript2.sh\\n#!/bin/bash\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri=sqlite:///mlflow.db --default-artifact-root=g3://zc-bucket/mlruns/\\nCreate a wrapper script to run above 2 scripts:\\n>\\twrapper_script.sh\\n#!/bin/bash\\n# Start the first process\\n./script1.sh &\\n# Start the second process\\n./script2.sh &\\n# Wait for any process to exit\\nwait -n\\n# Exit with status of process that exited first\\nexit $?\\nGive executable permissions to all scripts:\\nchmod +x *.sh\\nNow we can define last line of Dockerfile as:\\n> \\tDockerfile\\nCMD ./wrapper_script.sh\\nDont forget to expose all ports defined by services!', 'section': 'Module 4: Deployment', 'question': 'Running multiple services in a Docker container', 'course': 'mlops-zoomcamp'}}, {'_index': 'course-questions', '_id': 'aRacTJABVfXUHjPwybdN', '_score': 64.40936, '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I copy files from a different folder into docker container’s working directory?', 'course': 'machine-learning-zoomcamp'}}]}})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aed55e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To execute a command in a running Docker container, you can use the `docker exec` command. Here are the steps:\\n\\n1. List the running containers to find the `container-id`:\\n   ```\\n   docker ps\\n   ```\\n\\n2. Execute a command in the specific container using `docker exec`. For example, to start a bash session in the container, use:\\n   ```\\n   docker exec -it <container-id> bash\\n   ```\\n\\nThis will allow you to interact with the running container and run any required commands within it.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "320e3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question\", \"text\"],\n",
    "                        \"boost\": 4,\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46caf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results= elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer, search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0447ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I debug a docker container?'\n",
    "ans, search_results = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "372c73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Solution\\nThis error was because there was another instance of gunicorn running. So I thought of removing this along with the zoomcamp_test image. However, it didn’t let me remove the orphan container. So I did the following\\nRunning the following commands\\ndocker ps -a <to list all docker containers>\\ndocker images <to list images>\\ndocker stop <container ID>\\ndocker rm <container ID>\\ndocker rmi image\\nI rebuilt the Docker image, and ran it once again; this time it worked correctly and I was able to serve the test script to the endpoint.',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How to fix error after running the Docker run command',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'I wanted to understand how lambda container images work in depth and how lambda functions are initialized, for this reason, I found the following documentation\\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html\\nhttps://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html\\nAdded by Alejandro aponte',\n",
       "  'section': '9. Serverless Deep Learning',\n",
       "  'question': 'How do Lambda container images work?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response.choices[0].message.content\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1cfdaea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q5\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "872295e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question\", \"text\"],\n",
    "                        \"boost\": 4,\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = f\"\"\"\n",
    "                                Q: {doc['question']}\\n\\n\n",
    "                                A: {doc['text']}\\n\\n\n",
    "                            \"\"\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1507a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results= elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5205b8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9dnYBRZ6w5P4biTfSfyel32alUahb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To execute a command in a running Docker container, you typically use the `docker exec` command. Unfortunately, the provided CONTEXT did not contain specific information or instructions about executing commands in a running Docker container. \\n\\nHowever, in general, you can use the following command structure:\\n\\n```sh\\ndocker exec -it <container_id_or_name> <command>\\n```\\n\\nFor example, to run a shell inside a container, you can use:\\n\\n```sh\\ndocker exec -it <container_id_or_name> /bin/bash\\n```\\n\\nOr, if the container has sh instead of bash:\\n\\n```sh\\ndocker exec -it <container_id_or_name> /bin/sh\\n```\\n\\nReplace `<container_id_or_name>` with the actual ID or name of your running Docker container and `<command>` with the command you want to execute.', role='assistant', function_call=None, tool_calls=None))], created=1719272291, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_3e7d703517', usage=CompletionUsage(completion_tokens=168, prompt_tokens=205, total_tokens=373))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'How do I execute a command in a running docker container?'\n",
    "ans, prompt = rag(query)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d782d2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b6f1c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: How do I execute a command in a running docker container?\\n\\nCONTEXT:\\n\\n                                Q: I can’t create the environment on AWS Elastic Beanstalk with the command proposed during the video\\n\\n\\n                                A: I struggled with the command :\\neb init -p docker tumor-diagnosis-serving -r eu-west-1\\nWhich resulted in an error when running : eb local run --port 9696\\nERROR: NotSupportedError - You can use \"eb local\" only with preconfigured, generic and multicontainer Docker platforms.\\nI replaced it with :\\neb init -p \"Docker running on 64bit Amazon Linux 2\" tumor-diagnosis-serving -r eu-west-1\\nThis allowed the recognition of the Dockerfile and the build/run of the docker container.\\nAdded by Mélanie Fouesnard'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a1a8c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "73b7d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e71c3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63842,\n",
       " 261,\n",
       " 4165,\n",
       " 14029,\n",
       " 29186,\n",
       " 13,\n",
       " 30985,\n",
       " 290,\n",
       " 150339,\n",
       " 4122,\n",
       " 402,\n",
       " 290,\n",
       " 31810,\n",
       " 8099,\n",
       " 591,\n",
       " 290,\n",
       " 40251,\n",
       " 7862,\n",
       " 558,\n",
       " 8470,\n",
       " 1606,\n",
       " 290,\n",
       " 19719,\n",
       " 591,\n",
       " 290,\n",
       " 31810,\n",
       " 8099,\n",
       " 1261,\n",
       " 55959,\n",
       " 290,\n",
       " 150339,\n",
       " 364,\n",
       " 107036,\n",
       " 25,\n",
       " 3253,\n",
       " 621,\n",
       " 357,\n",
       " 15792,\n",
       " 261,\n",
       " 6348,\n",
       " 306,\n",
       " 261,\n",
       " 6788,\n",
       " 62275,\n",
       " 9282,\n",
       " 1715,\n",
       " 10637,\n",
       " 50738,\n",
       " 1402,\n",
       " 2419,\n",
       " 1486,\n",
       " 25,\n",
       " 357,\n",
       " 665,\n",
       " 1573,\n",
       " 2501,\n",
       " 290,\n",
       " 5870,\n",
       " 402,\n",
       " 40229,\n",
       " 88516,\n",
       " 2439,\n",
       " 27098,\n",
       " 2082,\n",
       " 483,\n",
       " 290,\n",
       " 6348,\n",
       " 17994,\n",
       " 3354,\n",
       " 290,\n",
       " 3823,\n",
       " 2499,\n",
       " 2419,\n",
       " 355,\n",
       " 25,\n",
       " 357,\n",
       " 52720,\n",
       " 483,\n",
       " 290,\n",
       " 6348,\n",
       " 10039,\n",
       " 1113,\n",
       " 6327,\n",
       " 533,\n",
       " 79,\n",
       " 62275,\n",
       " 40770,\n",
       " 2469,\n",
       " 34930,\n",
       " 12635,\n",
       " 199516,\n",
       " 533,\n",
       " 81,\n",
       " 5658,\n",
       " 78416,\n",
       " 12,\n",
       " 16,\n",
       " 198,\n",
       " 34405,\n",
       " 32871,\n",
       " 306,\n",
       " 448,\n",
       " 2915,\n",
       " 1261,\n",
       " 6788,\n",
       " 712,\n",
       " 17254,\n",
       " 2698,\n",
       " 2461,\n",
       " 2230,\n",
       " 447,\n",
       " 220,\n",
       " 48806,\n",
       " 21,\n",
       " 198,\n",
       " 7751,\n",
       " 25,\n",
       " 4037,\n",
       " 33833,\n",
       " 2255,\n",
       " 533,\n",
       " 1608,\n",
       " 665,\n",
       " 1199,\n",
       " 392,\n",
       " 1113,\n",
       " 2698,\n",
       " 1,\n",
       " 1606,\n",
       " 483,\n",
       " 876,\n",
       " 129656,\n",
       " 11,\n",
       " 21081,\n",
       " 326,\n",
       " 74200,\n",
       " 645,\n",
       " 2573,\n",
       " 91238,\n",
       " 18921,\n",
       " 558,\n",
       " 40,\n",
       " 21009,\n",
       " 480,\n",
       " 483,\n",
       " 10039,\n",
       " 1113,\n",
       " 6327,\n",
       " 533,\n",
       " 79,\n",
       " 392,\n",
       " 133534,\n",
       " 6788,\n",
       " 402,\n",
       " 220,\n",
       " 2220,\n",
       " 6516,\n",
       " 9529,\n",
       " 21117,\n",
       " 220,\n",
       " 17,\n",
       " 1,\n",
       " 40770,\n",
       " 2469,\n",
       " 34930,\n",
       " 12635,\n",
       " 199516,\n",
       " 533,\n",
       " 81,\n",
       " 5658,\n",
       " 78416,\n",
       " 12,\n",
       " 16,\n",
       " 198,\n",
       " 2500,\n",
       " 9279,\n",
       " 290,\n",
       " 25995,\n",
       " 328,\n",
       " 290,\n",
       " 91238,\n",
       " 2318,\n",
       " 326,\n",
       " 290,\n",
       " 3024,\n",
       " 133264,\n",
       " 328,\n",
       " 290,\n",
       " 62275,\n",
       " 9282,\n",
       " 558,\n",
       " 27387,\n",
       " 656,\n",
       " 194741,\n",
       " 13621,\n",
       " 140980,\n",
       " 268,\n",
       " 172992]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1300949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
